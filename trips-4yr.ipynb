{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce21fb61",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f343ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6adc10",
   "metadata": {},
   "source": [
    "## Connecting to the folder containing the csv files, combining them into single dataframe for years 2018-2020 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c100add8",
   "metadata": {},
   "source": [
    "**Important Note-**\n",
    "\n",
    "-All the csv files of trip data are split into two folders because of huge size to process together. \n",
    "\n",
    "-This spliting is done on the basis of file names. All the csv file names like 'Divvy_Trips_2015_07.csv' are stored in one      folder and the remaining csv files having names like '202004-divvy-tripdata.csv' are stored in another folder. \n",
    "\n",
    "-This is done for convenience of handling the data.\n",
    "\n",
    "Folder 1 = All csv files having names like '202004-divvy-tripdata.csv'\n",
    "\n",
    "Folder 2 = All csv files having names like 'Divvy_Trips_2015_07.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ac42ab2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   01 - Rental Details Rental ID 01 - Rental Details Local Start Time   \n",
      "0                     17536702.0                  2018-01-01 00:12:00  \\\n",
      "1                     17536703.0                  2018-01-01 00:41:35   \n",
      "2                     17536704.0                  2018-01-01 00:44:46   \n",
      "3                     17536705.0                  2018-01-01 00:53:10   \n",
      "4                     17536706.0                  2018-01-01 00:53:37   \n",
      "\n",
      "  01 - Rental Details Local End Time  01 - Rental Details Bike ID   \n",
      "0                2018-01-01 00:17:23                       3304.0  \\\n",
      "1                2018-01-01 00:47:52                       5367.0   \n",
      "2                2018-01-01 01:33:10                       4599.0   \n",
      "3                2018-01-01 01:05:37                       2302.0   \n",
      "4                2018-01-01 00:56:40                       3696.0   \n",
      "\n",
      "  01 - Rental Details Duration In Seconds Uncapped   \n",
      "0                                            323.0  \\\n",
      "1                                            377.0   \n",
      "2                                          2,904.0   \n",
      "3                                            747.0   \n",
      "4                                            183.0   \n",
      "\n",
      "   03 - Rental Start Station ID 03 - Rental Start Station Name   \n",
      "0                          69.0         Damen Ave & Pierce Ave  \\\n",
      "1                         253.0    Winthrop Ave & Lawrence Ave   \n",
      "2                          98.0     LaSalle St & Washington St   \n",
      "3                         125.0           Rush St & Hubbard St   \n",
      "4                         129.0      Blue Island Ave & 18th St   \n",
      "\n",
      "   02 - Rental End Station ID    02 - Rental End Station Name   User Type   \n",
      "0                       159.0       Claremont Ave & Hirsch St  Subscriber  \\\n",
      "1                       325.0  Clark St & Winnemac Ave (Temp)  Subscriber   \n",
      "2                       509.0             Troy St & North Ave  Subscriber   \n",
      "3                       364.0            Larrabee St & Oak St  Subscriber   \n",
      "4                       205.0            Paulina St & 18th St  Subscriber   \n",
      "\n",
      "   ... ended_at  start_station_name  start_station_id end_station_name   \n",
      "0  ...      NaN                 NaN               NaN              NaN  \\\n",
      "1  ...      NaN                 NaN               NaN              NaN   \n",
      "2  ...      NaN                 NaN               NaN              NaN   \n",
      "3  ...      NaN                 NaN               NaN              NaN   \n",
      "4  ...      NaN                 NaN               NaN              NaN   \n",
      "\n",
      "  end_station_id  start_lat start_lng  end_lat end_lng  member_casual  \n",
      "0            NaN        NaN       NaN      NaN     NaN            NaN  \n",
      "1            NaN        NaN       NaN      NaN     NaN            NaN  \n",
      "2            NaN        NaN       NaN      NaN     NaN            NaN  \n",
      "3            NaN        NaN       NaN      NaN     NaN            NaN  \n",
      "4            NaN        NaN       NaN      NaN     NaN            NaN  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['01 - Rental Details Rental ID', '01 - Rental Details Local Start Time',\n",
       "       '01 - Rental Details Local End Time', '01 - Rental Details Bike ID',\n",
       "       '01 - Rental Details Duration In Seconds Uncapped',\n",
       "       '03 - Rental Start Station ID', '03 - Rental Start Station Name',\n",
       "       '02 - Rental End Station ID', '02 - Rental End Station Name',\n",
       "       'User Type', 'Member Gender',\n",
       "       '05 - Member Details Member Birthday Year', 'trip_id', 'start_time',\n",
       "       'end_time', 'bikeid', 'tripduration', 'from_station_id',\n",
       "       'from_station_name', 'to_station_id', 'to_station_name', 'usertype',\n",
       "       'gender', 'birthyear', 'ride_id', 'rideable_type', 'started_at',\n",
       "       'ended_at', 'start_station_name', 'start_station_id',\n",
       "       'end_station_name', 'end_station_id', 'start_lat', 'start_lng',\n",
       "       'end_lat', 'end_lng', 'member_casual'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = r'insert the folder path containing all trip data files of type-Divvy_Trips_2015_07.csv '  # Replace with your actual folder path\n",
    "# Initialize an empty list to hold DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv') and re.search( r'(?<!\\d)(2018|2019|2020)(?!\\d)', filename):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "# Combine all DataFrames into one\n",
    "if df_list:\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    print(combined_df.head())\n",
    "else:\n",
    "    print(\"⚠️ No matching files found or all failed to load.\")\n",
    "#viewing the dataset for correct columns\n",
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ab319",
   "metadata": {},
   "source": [
    "## Preprocessing the dataset and viewing the columns,size and data types  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71cf2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head()\n",
    "combined_df.shape[0]\n",
    "combined_df.dtypes\n",
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794d6a87",
   "metadata": {},
   "source": [
    "## Data Mapping and Integration into common format to prevent information loss\n",
    "   - Columns in dataset gave us the insight that records were stored in three different column formats and                            this insights led us to segregate the data followed by mapping and then integrating together into single columns \n",
    "   - This helped to prevent information loss and millions of records were uniqfied in common name format\n",
    "   - Entire dataset was split into 3 subsets and then data trasformations and cleaning was performed on each subset\n",
    "   - Therefore these subsets were concatenated together into a single dataframe without losing much information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7f6b9ff7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ride_id          started_at            ended_at  bikeid  trip_duration   \n",
      "0  17536702.0 2018-01-01 00:12:00 2018-01-01 00:17:23  3304.0          323.0  \\\n",
      "1  17536703.0 2018-01-01 00:41:35 2018-01-01 00:47:52  5367.0          377.0   \n",
      "2  17536704.0 2018-01-01 00:44:46 2018-01-01 01:33:10  4599.0         2904.0   \n",
      "3  17536705.0 2018-01-01 00:53:10 2018-01-01 01:05:37  2302.0          747.0   \n",
      "4  17536706.0 2018-01-01 00:53:37 2018-01-01 00:56:40  3696.0          183.0   \n",
      "\n",
      "  start_station_id           start_station_name end_station_id   \n",
      "0             69.0       Damen Ave & Pierce Ave          159.0  \\\n",
      "1            253.0  Winthrop Ave & Lawrence Ave          325.0   \n",
      "2             98.0   LaSalle St & Washington St          509.0   \n",
      "3            125.0         Rush St & Hubbard St          364.0   \n",
      "4            129.0    Blue Island Ave & 18th St          205.0   \n",
      "\n",
      "                 end_station_name member_casual gender rideable_type   \n",
      "0       Claremont Ave & Hirsch St        casual   Male           NaN  \\\n",
      "1  Clark St & Winnemac Ave (Temp)        casual   Male           NaN   \n",
      "2             Troy St & North Ave        casual   Male           NaN   \n",
      "3            Larrabee St & Oak St        casual   Male           NaN   \n",
      "4            Paulina St & 18th St        casual   Male           NaN   \n",
      "\n",
      "   start_lat  start_lng  end_lat  end_lng  \n",
      "0        NaN        NaN      NaN      NaN  \n",
      "1        NaN        NaN      NaN      NaN  \n",
      "2        NaN        NaN      NaN      NaN  \n",
      "3        NaN        NaN      NaN      NaN  \n",
      "4        NaN        NaN      NaN      NaN  \n"
     ]
    }
   ],
   "source": [
    "#Calculate the Na values to give distribution across columns\n",
    "combined_df.isna().sum() \n",
    "\n",
    "#subset 1\n",
    "dfa=combined_df[['01 - Rental Details Rental ID', '01 - Rental Details Local Start Time',\n",
    "       '01 - Rental Details Local End Time', '01 - Rental Details Bike ID',\n",
    "       '01 - Rental Details Duration In Seconds Uncapped',\n",
    "       '03 - Rental Start Station ID', '03 - Rental Start Station Name',\n",
    "       '02 - Rental End Station ID', '02 - Rental End Station Name',\n",
    "       'User Type', 'Member Gender']]\n",
    "#subset 2\n",
    "dfb=combined_df[['trip_id', 'start_time',\n",
    "       'end_time', 'bikeid', 'tripduration', 'from_station_id',\n",
    "       'from_station_name', 'to_station_id', 'to_station_name', 'usertype']]\n",
    "#subset 3\n",
    "dfc=combined_df[[ 'ride_id', 'rideable_type', 'started_at',\n",
    "       'ended_at', 'start_station_name', 'start_station_id',\n",
    "       'end_station_name', 'end_station_id', 'start_lat', 'start_lng',\n",
    "       'end_lat', 'end_lng', 'member_casual']]\n",
    "\n",
    "#Removal of Na values in each subset \n",
    "a=dfa.dropna()\n",
    "b=dfb.dropna()\n",
    "c=dfc.dropna()\n",
    "\n",
    "#Column transformations and renaming of columns in these subsets\n",
    "a=a.rename(columns={'01 - Rental Details Rental ID':'ride_id','01 - Rental Details Local Start Time':'started_at',\n",
    "        '01 - Rental Details Local End Time':'ended_at','01 - Rental Details Bike ID':'bikeid',\n",
    "        '01 - Rental Details Duration In Seconds Uncapped':'trip_duration',\n",
    "        '03 - Rental Start Station ID':'start_station_id','03 - Rental Start Station Name':'start_station_name',\n",
    "        '02 - Rental End Station ID':'end_station_id','02 - Rental End Station Name':'end_station_name',\n",
    "        'User Type':'member_casual','Member Gender':'gender','05 - Member Details Member Birthday Year':'birth_year'})\n",
    "\n",
    "b=b.rename(columns={'trip_id':'ride_id','start_time':'started_at','end_time':'ended_at',\n",
    "            'tripduration':'trip_duration','from_station_id':'start_station_id',\n",
    "            'from_station_name':'start_station_name','to_station_id':'end_station_id',\n",
    "            'to_station_name':'end_station_name','usertype':'member_casual'})\n",
    "\n",
    "#Changing data format of certain columns of subset 3\n",
    "c[['started_at','ended_at']]=pd.to_datetime(c[['started_at','ended_at']].stack(),\n",
    "                           infer_datetime_format=True,format='%m/%d/%Y %H:%M').unstack()\n",
    "\n",
    "#Adding new column in subset 3 and by making transformation on existing ones\n",
    "c['trip_duration']=(c.ended_at-c.started_at).dt.total_seconds()/3600\n",
    "c['trip_duration'].dtype\n",
    "\n",
    "#Data integration of certain values in column into single category for subset 1 and 2\n",
    "a['member_casual']= np.where(a['member_casual']=='Subscriber', 'member', 'casual')\n",
    "b['member_casual']= np.where(b['member_casual']=='Subscriber', 'member', 'casual')\n",
    "\n",
    "#Data Integration into single dataframe by concatenating all subsets\n",
    "clean=pd.concat([a,b,c], ignore_index=True)\n",
    "\n",
    "#Changing data types of columns for optimizing memory \n",
    "clean=clean.astype({'ride_id':'string','started_at':'datetime64[ns]','ended_at':'datetime64[ns]','bikeid':'string',\n",
    "                    'start_station_name':'string','end_station_name':'string',\n",
    "                      'start_station_id':'string','end_station_id':'string',\n",
    "                     'rideable_type':'category','gender':'category'})\n",
    "clean['trip_duration'] = clean['trip_duration'].str.replace(',', '', regex=False).astype(float)\n",
    "\n",
    "#Sorting the cleaned dataset by dates in ascending order\n",
    "clean = clean.sort_values(by=['started_at', 'ended_at'], ascending=True)\n",
    "print(clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028d2609",
   "metadata": {},
   "source": [
    "## Saving the cleaned dataset in your local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ddd7b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned data containing the trips from years 2018-2020 \n",
    "clean.to_csv('insert the file path of csv file to store with name like-trips_18-20.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b477243",
   "metadata": {},
   "source": [
    "## Importing the dataset from year- 2018-2020 and 2020-2023 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f74e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#reading the trip data from years 2020-2023 \n",
    "df1=pd.read_csv('insert the file path of csv file like- trips_20-23.csv')  # contains the trip data stored in csv file from previous jupyter notebook\n",
    "#reading the trip data from years 2018-2020\n",
    "df=pd.read_csv('insert the file path of csv file like trips_18-20.csv')   # contains the data stored in csv from year 2018-2020   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cd9a92",
   "metadata": {},
   "source": [
    "## Data pre-processing and profiling with correct mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e559e47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                     int64\n",
       "ride_id               string[python]\n",
       "started_at            datetime64[ns]\n",
       "ended_at              datetime64[ns]\n",
       "bikeid                       float64\n",
       "trip_duration                float64\n",
       "start_station_id      string[python]\n",
       "start_station_name    string[python]\n",
       "end_station_id        string[python]\n",
       "end_station_name      string[python]\n",
       "member_casual               category\n",
       "gender                        object\n",
       "rideable_type               category\n",
       "start_lat                    float64\n",
       "start_lng                    float64\n",
       "end_lat                      float64\n",
       "end_lng                      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df1.astype({'ride_id':'string','started_at':'datetime64[ns]','ended_at':'datetime64[ns]',\n",
    "                    'start_station_name':'string','end_station_name':'string',\n",
    "                      'start_station_id':'string','end_station_id':'string',\n",
    "                     'rideable_type':'category','member_casual':'category'})\n",
    "print(df1.dtypes)\n",
    "\n",
    "df=df.astype({'ride_id':'string',\n",
    "                    'start_station_name':'string','end_station_name':'string',\n",
    "                      'start_station_id':'string','end_station_id':'string',\n",
    "                     'rideable_type':'category','member_casual':'category'})\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd5c7d3",
   "metadata": {},
   "source": [
    "## Combining the datasets into single dataframe containing years 2018-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20f3676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining both the datasets containing years:- 2018-2020 and 2020-2023\n",
    "mdf=pd.concat([df,df1], ignore_index=True)\n",
    "#adding columns for year and month\n",
    "mdf['year']=mdf['ended_at'].dt.year\n",
    "mdf['month']=mdf['ended_at'].dt.strftime('%B')\n",
    "#Converting duration in seconds column into hours \n",
    "mdf['trip_duration']=(mdf.ended_at-mdf.started_at).dt.total_seconds()/3600\n",
    "mdf['trip_duration'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a742a991",
   "metadata": {},
   "source": [
    "## Selecting the data for analysis containing years-2018-2021 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "03d7fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_4yr=mdf.query('2018 <= year <= 2021')\n",
    "trips_4yr.shape[0]\n",
    "trips_4yr['ride_id']='\"'+ trips_4yr['ride_id'] + '\"'\n",
    "#saving the data in csv file for years 2018-2021\n",
    "trips_4yr.to_csv('insert the file path for storing the combined data with names like- trips_4yr.csv ',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
